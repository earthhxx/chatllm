import { GoogleGenAI } from "@google/genai";

// The client gets the API key from the environment variable `GEMINI_API_KEY`.
const ai = new GoogleGenAI(
    { apiKey: process.env.LLM_API_KEY }
);

type SendToLLMOptions = {
    prompt: string;
    contextChunks?: string[];
};

type LLMResponse = {
    answer: unknown;
};

export async function sendToLLM(
    options: SendToLLMOptions
): Promise<LLMResponse> {
    const { prompt, contextChunks = [] } = options;

    console.log("üü¢ [sendToLLM] start");
    console.log("üü¢ [sendToLLM] prompt:", prompt);
    console.log("üü¢ [sendToLLM] context chunks:", contextChunks.length);

    // ‡∏£‡∏ß‡∏° context ‡∏à‡∏≤‡∏Å PDF
    const contextText = contextChunks.join("\n\n---\n\n");

    const fullPrompt = `
                        ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ AI
                        ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤ "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"

                        [‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•]
                        ${contextText}

                        [‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°]
                        ${prompt}
                        `.trim();

    try {
        const result = await ai.models.generateContent({
            model: "gemini-3-flash-preview",
            contents: fullPrompt,
        });

        const text = result.text;

        console.log("üü¢ [sendToLLM] success");

        return {
            answer: text,
        };
    } catch (err) {
        console.error("üî¥ [sendToLLM] failed", err);
        throw err;
    }
}
